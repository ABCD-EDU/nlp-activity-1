{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.parse import urlparse, unquote\n",
    "from tqdm.auto import tqdm\n",
    "import pathlib\n",
    "import functools\n",
    "import shutil\n",
    "import os\n",
    "from pathlib import Path\n",
    "import zipfile"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename(url):\n",
    "   urlparse(url).path\n",
    "   url_parsed = urlparse(url)\n",
    "   return unquote(Path(url_parsed.path).name)\n",
    "\n",
    "def download_file(url, filename):\n",
    "    r = requests.get(url, stream=True, allow_redirects=True)\n",
    "    if r.status_code != 200:\n",
    "        r.raise_for_status()  # Will only raise for 4xx codes, so...\n",
    "        raise RuntimeError(f\"Request to {url} returned status code {r.status_code}\")\n",
    "    file_size = int(r.headers.get('Content-Length', 0))\n",
    "\n",
    "    path = Path(filename).expanduser().resolve()\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    desc = \"(Unknown total file size)\" if file_size == 0 else \"\"\n",
    "    r.raw.read = functools.partial(r.raw.read, decode_content=True)  # Decompress if needed\n",
    "    with tqdm.wrapattr(r.raw, \"read\", total=file_size, desc=desc) as r_raw:\n",
    "        with path.open(\"wb\") as f:\n",
    "            shutil.copyfileobj(r_raw, f)\n",
    "\n",
    "    return path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(zip_file_path, extract_folder):\n",
    "   \n",
    "   with zipfile.ZipFile(zip_file_path, \"r\")  as zip_ref:\n",
    "      members = zip_ref.infolist()\n",
    "      with tqdm(total=len(members), desc=\"Extracting Files\") as pbar:\n",
    "         for member in members:\n",
    "            zip_ref.extract(member,f\"{extract_folder}\") \n",
    "            pbar.update(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checks if WIKITL is already downloaded else download and extract WikiTL\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_extracted_folder = \"wikitext-tl-39\" in os.listdir(\"../wiki_tl\")\n",
    "has_zipfile =  \"wikitext-tl-39.zip\" in os.listdir(\"../wiki_tl\") \n",
    "url = \"https://s3.us-east-2.amazonaws.com/blaisecruz.com/datasets/wikitext-tl-39/wikitext-tl-39.zip\"\n",
    "\n",
    "data_dir= \"../wiki_tl\"\n",
    "filename = f\"{data_dir}/{get_filename(url)}\"\n",
    "\n",
    "if has_extracted_folder==False:\n",
    "   print('True')\n",
    "   if has_zipfile:\n",
    "      extract(filename, data_dir)\n",
    "   else:\n",
    "      download_file(url, filename)\n",
    "      extract(filename, data_dir)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "folder_path = \"../wiki_tl/wikitext-tl-39\"\n",
    "# List to store the contents of all the files\n",
    "all_contents = []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        with open(os.path.join(folder_path, filename)) as f:\n",
    "            contents = f.read()\n",
    "            # Split the contents using whitespace\n",
    "            tokens = re.split(r'\\s+', contents)\n",
    "            # Remove tokens that are special characters\n",
    "            tokens = [token for token in tokens if not re.match(r'[^\\w\\s]+', token)]\n",
    "            # Remove periods and commas\n",
    "            tokens = [token.strip(\".,\") for token in tokens]\n",
    "            # Append the contents to the list\n",
    "            all_contents.extend(tokens)\n",
    "\n",
    "# Save the contents to a single file\n",
    "with open(\"preprocessed_wiki_tl.txt\", \"w\") as f:\n",
    "    f.write(\" \".join(all_contents))\n",
    "            \n",
    "            # do something with the contents of the file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
